<div align="center">

# ğŸ•µï¸ Confounder

**Measure what confounds, or know the limits of what you claim.**

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Tests](https://github.com/your-username/confounder/actions/workflows/ci.yml/badge.svg)](https://github.com/your-username/confounder/actions)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)

Confounder uses **LLMs + causal statistics** to detect hidden confounders in observational studies *before* they invalidate your results.

[The Problem](#-the-core-problem) Â· [Quick Start](#-quick-start) Â· [How It Works](#-how-it-works) Â· [Example Output](#-example-output) Â· [LLM vs Causal](#-llm-vs-causal) Â· [API](#-api)

</div>

---

## ğŸ§  Philosophy

- ğŸ  **Local-first** â€” Ollama is the default. Your data never leaves your machine.
- ğŸ”¬ **Scientifically rigorous** â€” Every LLM hypothesis is validated with real statistical tests.
- ğŸ§  **Knowledge-augmented** â€” LLMs propose confounders that pure statistics can't conceive of.
- âœ… **Actionable** â€” Concrete study design corrections, not generic warnings.
- ğŸš« **No telemetry** â€” All analysis happens locally. Zero data collection.

---

## ğŸ“– The Core Problem

You're running an observational study. You find:

> *"Treatment X increases outcome Y by 15%"*

But did it? Or is there a hidden confounder Z that causes both X and Y?

```
Naive model:     X â”€â”€â†’ Y           â† "Treatment causes outcome"

Reality:         Z â”€â”€â†’ X
                 Z â”€â”€â†’ Y           â† Z is doing the work.
                 X Â·Â·â†’ Y (weak)       Your 15% is spurious.
```

**Why current approaches fail:**

| Approach | Limitation |
|---|---|
| ğŸ“‰ **Pure statistics** | Can detect measured confounders, but *cannot* detect unmeasured ones |
| ğŸ§‘â€ğŸ”¬ **Domain experts** | Miss structural variables outside their immediate expertise |
| ğŸ¤– **Pure LLMs** | Hallucinate confounders without statistical grounding |

---

## ğŸš€ Quick Start

```bash
git clone https://github.com/your-username/confounder.git
cd confounder
pip install -e ".[dev]"
cp .env.example .env    # Configure LLM provider (default: Ollama)
```

Run a full confounder audit:

```bash
confounder check \
  --data study.csv \
  --treatment received_treatment \
  --outcome health_score \
  --question "Does the treatment improve health scores?" \
  --context background.md \
  --graph
```

---

## ğŸ—ï¸ How It Works

```
Dataset + Research Question + Background Context
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  LLM Candidate â”‚  â† Expert-prompted LLM proposes 5-10
           â”‚   Generation   â”‚    mechanistic confounder hypotheses
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Statistical  â”‚  â† OLS/Logit conditional independence
           â”‚   Validation   â”‚    tests prove or disprove each one
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚     Bias       â”‚  â† Naive vs. adjusted effect estimation
           â”‚  Quantifier    â”‚    calculates exact bias %
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Correction   â”‚  â† Control, stratify, sensitivity
           â”‚   Suggester    â”‚    bounds, or study redesign
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
              Audit Report
          + Interactive DAG
```

1. **LLM Candidate Brainstorming** â€” Feeds your research question, column names, and background context to an expert-prompted LLM. It thinks *mechanistically*: which variables strictly cause both treatment and outcome?

2. **Statistical Validation** â€” Fuzzy-matches the LLM's proposals against your dataset. If a candidate is measured, runs conditional independence tests (OLS/Logit) to mathematically prove or disprove the hypothesis with your actual data.

3. **Exact Bias Quantification** â€” Estimates the naive treatment effect and compares it to the adjusted estimate, calculating the exact percentage of bias introduced by each confirmed confounder.

4. **Sensitivity Bounds** â€” If the LLM proposes an *unmeasured* confounder, runs E-value sensitivity analysis to determine how strong that hidden variable would need to be to completely explain away your observed effect.

5. **Interactive DAGs** â€” Auto-generates `pyvis` network graphs highlighting exactly where the structural breaks are in your causal model.

---

## ğŸ“Š Example Output

```console
$ confounder check -d data.csv -t saw_feature -o spend -q "Does the new feature increase spend?"

ğŸ“‚ Loading study data from data.csv...
   1847 rows | Treatment: saw_feature | Outcome: spend

ğŸ§  Querying LLM for candidate confounders...

ğŸ”¬ Statistically validating 4 proposed confounders...
   âœ… 'user_activity' CONFIRMED as a confounder (p_T=0.003, p_Y<0.001)
   âŒ 'device_type' REJECTED. Not a confounder in this data.
   âŒ 'signup_source' REJECTED. Not a confounder in this data.

ğŸ§® Quantifying bias...

==================================================
=== Confounder Analysis Report ===
==================================================

Research Question: Does the new feature increase spend?

Naive Estimate: +12.3041

CRITICAL CONFOUNDERS DETECTED:

1. USER_ACTIVITY (MEASURED & CONFIRMED)
   Mechanism: Active users navigate more â†’ likelier to see feature.
              Active users naturally spend more.
   Estimated bias: +8.2014 (+66.7% of full effect)
   Evidence: p_treatment=0.0034, p_outcome<0.0001
   Recommendation: Include 'user_activity' as a covariate.

2. PARENTAL_INCOME (UNMEASURED)
   Mechanism: High income â†’ better devices â†’ more exposure.
              High income â†’ higher baseline spend.
   Sensitivity: Would need RR > 2.5 to invalidate result.
   Recommendation: Run sensitivity analysis in final paper.

âœ“ DAG saved to confounder_dag.html
```

---

## ğŸ”¬ LLM vs Causal

This is the core philosophical question Confounder answers: **what happens when you add rigorous causal inference on top of LLM reasoning?**

| | Raw LLM | Confounder (LLM + Causal) |
|---|---|---|
| **Proposes confounders** | âœ… Often 20+ candidates | âœ… Focused 5-10 with mechanistic reasoning |
| **Validates against data** | âŒ Cannot test hypotheses | âœ… OLS/Logit conditional independence |
| **Quantifies bias** | âŒ No numerical output | âœ… Exact % of naive effect explained |
| **Rejects false positives** | âŒ Everything "could be" a confounder | âœ… Statistical significance filtering |
| **Handles unmeasured** | âŒ "You should measure it" | âœ… Sensitivity bounds (E-values) |
| **Actionable output** | âš ï¸ Generic paragraphs | âœ… Specific corrections per confounder |
| **Reproducible** | âŒ Different answer each time | âœ… Same data â†’ same statistical result |

An LLM can tell you *"age might be a confounder."* Confounder tells you *"age IS a confounder â€” it explains 66.7% of your observed effect, and here's how to correct for it."*

**The gap between hypothesis and proof is where bad science lives. Confounder closes that gap.**

---

## ğŸŒ API

### CLI Commands

```bash
confounder check -d study.csv -t treatment -o outcome -q "Research question?" --graph
confounder providers    # Show available LLM providers
confounder --version
```

### REST API

```bash
uvicorn confounder.api.server:app --reload
```

| Method | Path | Description |
|---|---|---|
| `GET` | `/health` | Health check + version |
| `GET` | `/providers` | Available LLM providers |
| `POST` | `/check` | Full confounder audit |

### Python SDK

```python
from confounder.data.loader import load_study
from confounder.detection.validator import validate_candidates
from confounder.estimation.bias import estimate_bias

study = load_study("data.csv", "treatment", "outcome", "Does it work?")
# ... â†’ validate â†’ estimate â†’ report
```

See [CONTRIBUTING.md](CONTRIBUTING.md) for full API documentation.

---

## âš™ï¸ Supported Providers

| Provider | Config | Notes |
|---|---|---|
| `ollama` | Default | Local, private, free |
| `openai` | `OPENAI_API_KEY` | GPT-4o recommended |
| `anthropic` | `ANTHROPIC_API_KEY` | Claude 3.5 Sonnet |
| `groq` | `GROQ_API_KEY` | Fast inference |
| `mistral` | `MISTRAL_API_KEY` | Open-weight models |
| `together` | `TOGETHER_API_KEY` | Llama, Mixtral |

---

## ğŸ§ª Testing

41 tests across 7 modules:

| Module | Coverage |
|---|---|
| `test_data.py` | CSV loading, missing columns, min samples, variance |
| `test_llm.py` | JSON parsing, markdown stripping, schema validation |
| `test_detection.py` | Association tests, conditional independence, fuzzy matching |
| `test_estimation.py` | OLS bias calculation, sensitivity bounds |
| `test_correction.py` | Strategy generation, ranking, report creation |
| `test_cli.py` | Version, providers, invalid data, mocked E2E |
| `test_api.py` | Health check, providers, mocked /check |

```bash
pytest tests/ -v
```

---

## ğŸ“„ License

MIT License. See [LICENSE](LICENSE) for details.

---

<div align="center">

*"Measure what confounds, or know the limits of what you claim."*

</div>
